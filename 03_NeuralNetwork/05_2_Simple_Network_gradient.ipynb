{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c)   #개선\n",
    "    sum_exp_a = sum(np.exp(a-c))\n",
    "    y = exp_a/sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 ONE-HOT 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        np.random.seed(0) #항상 동일한 랜덤값 출력을 위함 (수업 목적)\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = simpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.6, 0.9]) # 입력\n",
    "t = np.array([0.0, 0.0, 1.0]) #정답, TARGET, 정답의 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W #어떤값으로 초기화 되어있는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력값을 이용하여 FORWARD 방향 연산해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.07523529  1.92089652 -0.2923073 ]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74088333 0.23357527 0.0255414 ]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동일한 입력값과 정답을 이용하여 loss 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6674507891066104"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.loss(x,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient_single_point(f, x, verbose=False): \n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    if verbose:\n",
    "        print('x.size={}'.format(x.size)) # (x0, x1) 을 입력으로 받음 --> 2\n",
    "       \n",
    "    for idx in range(x.size): #축별로 계산\n",
    "        v_keep = x[idx]\n",
    "        \n",
    "        # f(x+h) 계산\n",
    "        x[idx] = float(v_keep) + h #n차원 입력 중 해당 차원으로만 h를 더하고\n",
    "        fxh1 = f(x)\n",
    "        if verbose:\n",
    "            print(x, '-->', fxh1)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = float(v_keep) - h #n차원 입력 중 해당 차원으로만 h를 빼서\n",
    "        fxh2 = f(x)\n",
    "        if verbose:\n",
    "            print(x, '-->', fxh2)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h) #n차원 방향의 차분을 구함 !\n",
    "        x[idx] = v_keep # 값 복원\n",
    "        \n",
    "        if verbose:\n",
    "            print('grad[{}]={}'.format(idx, grad[idx]))\n",
    "            print()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, X):\n",
    "    if X.ndim == 1:\n",
    "        return numerical_gradient_single_point(f, X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        \n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = numerical_gradient_single_point(f, x)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고) lambda\n",
    "```\n",
    "lambda 인자리스트: 표현식\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w): #Loss 산의 높이\n",
    "    return net.loss(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위처럼 해도 되지만, 아래처럼 lambda 를 써서 간단히 하는 것도 좋은 방법. 단, 인자로 들어가는 w는 dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda w: net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW = numerical_gradient(f, net.W) # 6 방향의 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44452826  0.14014461 -0.58467287]\n",
      " [ 0.66679239  0.21021692 -0.87700931]]\n"
     ]
    }
   ],
   "source": [
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생각해보기\n",
    "* 각 숫자들의 의미를 생각해보세요 (2020/11/24일 수업)\n",
    "* 교재 135쪽 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같은 방식으로 W를 갱신할 수 있음\n",
    "```\n",
    "net.W = net.W - 0.01 * dW\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet2:\n",
    "    def __init__(self):\n",
    "        np.random.seed(0) #항상 동일한 랜덤값 출력을 위함 (수업 목적)\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        f = lambda w: net.loss(x, t)\n",
    "        dW = numerical_gradient(f, net.W) # 6 방향의 기울기\n",
    "        \n",
    "        return dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = simpleNet2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44452826,  0.14014461, -0.58467287],\n",
       "       [ 0.66679239,  0.21021692, -0.87700931]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.gradient(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습이 되기 전 랜덤값으로 초기화된 weight로 결과 맞추는지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.07523529,  1.92089652, -0.2923073 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74088333, 0.23357527, 0.0255414 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(net2.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(net2.predict(x))) #추론한 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(t) #정답 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(net2.predict(x))) == np.argmax(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "steps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the network !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6674507891066104"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "vloss = np.zeros((steps, 1))\n",
    "for i in range(steps):\n",
    "    grad = net2.gradient(x, t)\n",
    "    net2.W = net2.W - learning_rate * grad\n",
    "    \n",
    "    loss_i = net2.loss(x, t)\n",
    "    vloss[i] = loss_i\n",
    "    #print(i, grad)\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68123023, -1.00128894,  6.82546671],\n",
       "       [-4.42703066, -0.23461124,  7.7928152 ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.60679616344305e-06"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'lr = 0.1')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vloss)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('loss')\n",
    "plt.title('lr = {}'.format(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction / Infererence (추론과정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.59306573, -0.81192348, 11.10881371])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.57780093e-08, 6.65099633e-06, 9.99993293e-01])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(net2.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(net2.predict(x))) #추론한 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(net2.predict(x))) == np.argmax(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
